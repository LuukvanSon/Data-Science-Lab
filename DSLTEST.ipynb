{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import locale\n",
    "from yellowbrick.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\hp\\OneDrive\\Documenten\\Data Science Lab\\listings_summary.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column-specific preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop features irrelevant to price, based on intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'listing_url', 'host_neighbourhood', 'calendar_updated', 'host_picture_url', \n",
    "                                  'scrape_id', 'last_scraped', 'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url',\n",
    "                                  'host_id', 'host_url', 'host_name', 'host_about', 'host_thumbnail_url','calendar_last_scraped', \n",
    "                                  'license', 'jurisdiction_names', 'weekly_price', 'monthly_price'], axis = 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assuming model must be globally applicable, we remove all location based features as it is only Berlin, Germany based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['zipcode','street', 'neighbourhood', 'neighbourhood_cleansed', \n",
    "            'neighbourhood_group_cleansed', 'city' , 'state', 'market', \n",
    "            'smart_location', 'country_code', 'country', 'longitude', 'latitude'],axis = 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop 'free text' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['name', 'summary', 'space', 'description', 'experiences_offered', \n",
    "                                  'neighborhood_overview', 'notes', 'transit', 'transit', 'access', \n",
    "                                'interaction', 'house_rules'], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop features with a missing values percentage higher than 50% of the total amount of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
      "       'square_feet'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "missing_values_percentage = df.isnull().sum() / len(df)\n",
    "selected_features = missing_values_percentage[missing_values_percentage > 0.5].index\n",
    "print(selected_cols)\n",
    "df = df.drop(selected_features, axis = 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'host_listing_count' and 'host_total_listings_count' have only 26 non-similar values which are all NaN's, so we drop one of these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(sum((df.host_listings_count == df.host_total_listings_count) == False))\n",
    "# = Listing_Data.loc[((Listing_Data.host_listings_count == Listing_Data.host_total_listings_count) == False)]\n",
    "df = df.drop(['host_total_listings_count'], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features 'host_verifications' and 'amenities' removed due to complexity i.c.w. time limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['host_verifications', 'amenities'], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features 'host_since', 'first_review' and 'last_review' are all datetimes which we transform to numerical 'years since' features making them more suitable for prediction. After transformation, we drop the original features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_years_active</th>\n",
       "      <th>years_since_first_review</th>\n",
       "      <th>years_since_last_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_years_active  years_since_first_review  years_since_last_review\n",
       "0               14.0                       6.0                      4.0\n",
       "1               14.0                       4.0                      4.0\n",
       "2               14.0                      13.0                      6.0\n",
       "3               14.0                       9.0                      4.0\n",
       "4               13.0                      13.0                      4.0"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['host_since','first_review', 'last_review']]  = df[['host_since', 'first_review', 'last_review']].applymap(pd.to_datetime)\n",
    "\n",
    "df['host_years_active'] = (datetime.now() - df['host_since']).astype('timedelta64[Y]')\n",
    "df['years_since_first_review'] = (datetime.now() - df['first_review']).astype('timedelta64[Y]')\n",
    "df['years_since_last_review'] = (datetime.now() - df['last_review']).astype('timedelta64[Y]')\n",
    "\n",
    "df = df.drop(['host_since', 'first_review', 'last_review'], axis = 1)\n",
    "\n",
    "df[['host_years_active','years_since_first_review', 'years_since_last_review']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform 'host_location' into binary feature indicating whether host lives in city of property or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    f\n",
       "1    t\n",
       "2    f\n",
       "3    t\n",
       "4    t\n",
       "Name: host_in_city, dtype: object"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['host_in_city'] = df['host_location'].apply(lambda x:'t' if x == 'Berlin, Berlin, Germany' else 'f')\n",
    "df = df.drop(['host_location'], axis = 1)\n",
    "df['host_in_city'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For target variable 'price' and features 'security_deposit', 'cleaning_fee' and 'extra_people' remove $ and '.00' convert to float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['price', 'security_deposit', 'cleaning_fee','extra_people']] = df[['price', 'security_deposit', 'cleaning_fee','extra_people']].apply(lambda x:x.str[1:-3])\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "df[['price', 'security_deposit', 'cleaning_fee','extra_people']] = df[['price', 'security_deposit', 'cleaning_fee','extra_people']].astype(str).applymap(locale.atof)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As the range of categories of feature 'property_type' is very broad and unequally distributed we assign all categories apart from 'House' and 'Apartment' to category 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment                 20225\n",
      "Condominium                 612\n",
      "Loft                        460\n",
      "House                       398\n",
      "Serviced apartment          175\n",
      "Hostel                      128\n",
      "Townhouse                    99\n",
      "Guest suite                  74\n",
      "Bed and breakfast            64\n",
      "Guesthouse                   57\n",
      "Hotel                        50\n",
      "Other                        47\n",
      "Boutique hotel               43\n",
      "Bungalow                     20\n",
      "Boat                         17\n",
      "Tiny house                   12\n",
      "Houseboat                    11\n",
      "Camper/RV                    11\n",
      "Villa                        10\n",
      "Aparthotel                    7\n",
      "Pension (South Korea)         7\n",
      "Cabin                         6\n",
      "Cottage                       4\n",
      "Resort                        3\n",
      "Castle                        2\n",
      "Casa particular (Cuba)        2\n",
      "Train                         2\n",
      "Tipi                          1\n",
      "Chalet                        1\n",
      "Barn                          1\n",
      "Island                        1\n",
      "In-law                        1\n",
      "Cave                          1\n",
      "Name: property_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['property_type'].value_counts())\n",
    "df.loc[~df['property_type'].isin(['House', 'Apartment']), 'property_type'] = 'Other'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype-specific preprocessing (scaling, imputing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separate target variable 'price' from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,df.columns != 'price']\n",
    "y = df['price']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform train/test (80/20) split before datatype-specific preprocessing to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distinguish numerical, binary and nominal features and perform completeness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num_features = ['host_listings_count', 'host_years_active', 'years_since_first_review', \n",
    "                'years_since_last_review', 'accommodates', 'bathrooms', 'bedrooms', 'beds', \n",
    "                'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people',\n",
    "                'minimum_nights', 'maximum_nights','availability_30', 'availability_60', \n",
    "                'availability_90', 'availability_365', 'number_of_reviews', 'review_scores_rating', \n",
    "                'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', \n",
    "                'review_scores_communication', 'review_scores_location', 'review_scores_value', \n",
    "                'calculated_host_listings_count', 'reviews_per_month'] \n",
    "bin_features = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'is_location_exact',\n",
    "                'has_availability', 'requires_license','instant_bookable', 'is_business_travel_ready',\n",
    "                'require_guest_profile_picture', 'require_guest_phone_verification', 'host_in_city']\n",
    "nom_features = ['property_type', 'room_type', 'bed_type','cancellation_policy']\n",
    "\n",
    "all_features = num_features + bin_features + nom_features\n",
    "completeness_check = len(X_train.drop(all_features, axis = 1).columns)\n",
    "print(completeness_check)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create customized encoder function that replaces 't' and 'f' into binary variables 1 respectively 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_replacer(df):\n",
    "    return df.replace({'t': 1, 'f': 0})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create pipeline for each datatype: StandardScaler and KNNImputer (missing values) for numerical features, Encoder and Imputer for binary features and Encoder for nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('imputer', KNNImputer())])\n",
    "bin_pipeline = Pipeline([('encoder', FunctionTransformer(binary_replacer)),\n",
    "                 ('imputer', SimpleImputer(strategy = 'most_frequent'))])\n",
    "nom_pipeline = Pipeline([('encoder', OneHotEncoder(sparse = False, drop = 'first'))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge all transformer pipelines into one transformer pipeline, where each pipeline is only executed with the corresponding feature data with a specific datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transformer = ColumnTransformer([\n",
    "        (\"numerical\",num_pipeline, num_features),\n",
    "        (\"binary\", bin_pipeline, bin_features),\n",
    "        (\"nominal\",nom_pipeline, nom_features)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate ML algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extend pipeline with baseline model: Linear Regression and fit the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lin_regr = Pipeline([('preprocessing', combined_transformer), \n",
    "                     ('model', LinearRegression())])\n",
    "lin_regr_fit = pipe_lin_regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lin_regr_test = lin_regr_fit.predict(X_test)\n",
    "y_pred_lin_regr_train = lin_regr_fit.predict(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extend pipeline with Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rand_forest = Pipeline([('preprocessing', combined_transformer), \n",
    "                     ('model', RandomForestRegressor())])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform small hyperparameter optimization using a 5-fold cross-validated grid search over manually selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "    'model__n_estimators': [50,100,150],\n",
    "    'model__max_depth': [5, 10, 30],\n",
    "    'model__max_features':['sqrt', 'log2']\n",
    "}]\n",
    "\n",
    "grid_cv_rand_forest = GridSearchCV(pipe_rand_forest, param_grid, scoring=make_scorer(mean_squared_error), cv=5)\n",
    "grid_cv_rand_forest.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrieve 'Best Parameters' and 'Best Score' and fit best model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'model__max_depth': 5, 'model__max_features': 'log2', 'model__n_estimators': 50}\n",
      "Best Score:  26491.67207229123\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", grid_cv_rand_forest.best_params_)\n",
    "print(\"Best Score: \", grid_cv_rand_forest.best_score_)\n",
    "\n",
    "y_pred_rand_forest_test = grid_cv_rand_forest.predict(X_test)\n",
    "y_pred_rand_forest_train = grid_cv_rand_forest.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Root Mean Squared Error Train:  232.59387774559005\n",
      "LR R-squared Train: 0.06267049596699192\n",
      "LR Root Mean Squared Error Test:  166.91826197446642\n",
      "LR R-squared Test: -0.030920707588969698\n",
      "RF Root Mean Squared Error Train:  140.0087885180471\n",
      "RF R-squared Train: 0.6603697815653287\n",
      "RF Root Mean Squared Error Test:  130.8568844029364\n",
      "RF R-squared Test: 0.36640650914278394\n"
     ]
    }
   ],
   "source": [
    "rmse_lr_train = metrics.mean_squared_error(y_train, y_pred_lin_regr_train, squared = False)\n",
    "r2_lr_train= metrics.r2_score(y_train, y_pred_lin_regr_train)\n",
    "rmse_lr_test = metrics.mean_squared_error(y_test, y_pred_lin_regr_test, squared = False)\n",
    "r2_lr_test = metrics.r2_score(y_test, y_pred_lin_regr_test)\n",
    "\n",
    "rmse_rf_train = metrics.mean_squared_error(y_train, y_pred_rand_forest_train, squared = False)\n",
    "r2_rf_train = metrics.r2_score(y_train, y_pred_rand_forest_train)\n",
    "rmse_rf_test = metrics.mean_squared_error(y_test, y_pred_rand_forest_test, squared = False)\n",
    "r2_rf_test = metrics.r2_score(y_test, y_pred_rand_forest_test)\n",
    "print(\"LR Root Mean Squared Error Train: \", rmse_lr_train)\n",
    "print(\"LR R-squared Train:\", r2_lr_train)\n",
    "print(\"LR Root Mean Squared Error Test: \", rmse_lr_test)\n",
    "print(\"LR R-squared Test:\", r2_lr_test)\n",
    "\n",
    "print(\"RF Root Mean Squared Error Train: \", rmse_rf_train)\n",
    "print(\"RF R-squared Train:\", r2_rf_train)\n",
    "print(\"RF Root Mean Squared Error Test: \", rmse_rf_test)\n",
    "print(\"RF R-squared Test:\", r2_rf_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
